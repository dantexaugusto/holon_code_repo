import os
from dotenv import load_dotenv
load_dotenv()
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters
import chama_birth as chama


#Assistente Chama t.me/assistente_chama_bot
BOT_TOKEN = os.getenv('BOT_TOKEN')

# FunÃ§Ã£o para o comando /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)
    welcomingText = chama.frontEnd_usrMessage_receiver(user_id, 'OlÃ¡')
    await update.message.reply_text(welcomingText)

async def responder(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)
    user_msg = update.message.text
    print(f"UsuÃ¡rio: {user_msg}")

    # Aqui vocÃª insere sua chamada Ã  OpenAI (com o system_message da Chama)
    resposta = f"{chama.frontEnd_usrMessage_receiver(user_id, user_msg)} ðŸŒ±"  # placeholder

    await update.message.reply_text(resposta)

app = ApplicationBuilder().token(BOT_TOKEN).build()
app.add_handler(CommandHandler("start", start))
app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, responder))

print("ðŸ”¥ Chama estÃ¡ escutando com alma...")
app.run_polling()

